# Data Science Projects

## Credibility: Some projects below were part of Year 3 Imperial College Mathematics Data Science Module, in which I ranked 1st out of 200 students

---
# [Project 1: Exploring unsupervised graph-based learning methods, clustering methods and neural networks in Python](https://github.com/leonwu4951/Data-Science/blob/master/Graph-Cluster-NN/)

## Overview
- Clustering of academic papers using K-Means, comparing different scoring metrics and analyzing optimal number of clusters and randomness in K-Means
- Graph-based learning methods for clustering including community detection and centrality measures
- Image classification of clothing items using unsupervised methods
- Used PCA to visualise clustering of clothing items and centroids
- Comparison of kNN, hierachical clustering and neural networks for supervised image classification
- Comparison of MLP neural networks and CNNs
- Alteration of CNNs using dropout, other layers and alterations to kernel sizes to increase accuracy
- K-Fold Stratified Cross-Validation used throughout

Community Detection using CNM  |  Clustering visualised with PCA
:-------------------------:|:-------------------------:
![](https://github.com/leonwu4951/Data-Science/blob/master/Graph-Cluster-NN/Project%203_files/Project%203_73_0.png)  |  ![](https://github.com/leonwu4951/Data-Science/blob/master/Graph-Cluster-NN/Project%203_files/Project%203_121_0.png)
---


---
# [Project 2: Exploring supervised Random Forests, Support Vector Machines and Neural Network in-depth for classification on noisy data in Python](https://github.com/leonwu4951/Data-Science/blob/master/RF-SVM-NN/)

## Overview
- Data Balancing and Standardisation Methodologies for predicting car ratings
- Explaining K-Fold Stratified Cross-Validation
- Random Forest optimasation for number of trees, depth and number of split predictors
- Support Vector Machines: optimisation of kernels (linear, polynomial and RBF)
- Neural Network optimsation for batch size, learning rate and dropout

Number of Trees for Random Forest  |  Hyperparameters of RBF kernel SVM
:-------------------------:|:-------------------------:
![](https://github.com/leonwu4951/Data-Science/blob/master/RF-SVM-NN/Project%202_files/Project%202_32_0.png)  |  ![](https://github.com/leonwu4951/Data-Science/blob/master/RF-SVM-NN/Project%202_files/Project%202_71_0.png)
---


---
# [Project 3: Exporing regression and classification methods including ridge and logitstic regression and Naïve Bayes classifiers in Python](https://github.com/leonwu4951/Data-Science/blob/master/Regression-Classification/)

## Overview
- Goal: Predicting climbing success rate from weather predictors
- Data cleaning using Pandas
- Exploratory data analysis
- Compared regression methods including linear and ridge
- Compared classifiers including Logistic Regression and Naïve Bayes using different metrics

Ridge Regression hyperparameter tuning (CV)  |  Ridge Predictors against penalty parameter
:-------------------------:|:-------------------------:
![](https://github.com/leonwu4951/Data-Science/blob/master/Regression-Classification/Project%201_files/Project%201_25_1.png)  |  ![](https://github.com/leonwu4951/Data-Science/blob/master/Regression-Classification/Project%201_files/Project%201_25_2.png)
---

---
# [Project 4: Recommender System for Academic Papers using Multidimensional Scaling in R](https://github.com/leonwu4951/Paper-Configurations)

## Overview
- Goal: Reveal configurations of academic papers so that a user can find targeted lists of research materials
- Dissimilarity measures
- Data scraping using unix and Google Scholar
- Classical and Ordinal Scaling, analysis of eigenvalues
- K-Means Clustering of final configurations for labelling

Word Counts in Papers  |  Heatmap of Word Frequencies for Each Paper
:-------------------------:|:-------------------------:
![](https://github.com/leonwu4951/Paper-Configurations/blob/master/figures/1.jpg)  |  ![](https://github.com/leonwu4951/paper-configurations/blob/master/figures/2.png)
---




